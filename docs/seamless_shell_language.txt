Caching:
A cache is a smart JSON structure
Every context is associated with a cache
This is always pcache[name], where pcache is the parent cache
 and name is the child name of the context.
Every cell is either uncached, hash-cached or fully cached.
Cells are by default uncached, they can be set to fully cached.
 When they are, their dependencies become hash-cached. As long as the hash cache
 of the dependency does not change, there is a cache hit and the cell will not
 be recomputed but retrieved from cache
A hash-cache is:
  - If the cell is independent, it is the hash of the cell's contents
  - If the cell is dependent, it is the hash-cache of its dependencies.
  - If the cell is independent-but-binary, or dependent-but-edited, then caching
    becomes impossible, and a warning is issued

Caching is useful for three cases:
- Channel iteration, which causes (input) cells to change rapidly. It is useful to cache the computation
 for each channel item, so that modifying the channel or file reloading does not trigger a full recompute
- Mounting the cache to the file system
- The Seamless Shell Language, which operates on cache items rather than cells

Subcaching:
You can specify a subcache name, and the subcache can be computed from input pins:
ctx.CACHE.set_subcache["{input1}-{input2}"]

Shell language:
@declare foo CMD #foo is a command line script with a single output
@declare foo CMD SYNTAX -o $OUTPUT  #foo is a command line script with a single output, but instead of "foo > output", it wants "foo -o $OUTPUT"
@declare foo CMD CAPTURE #foo may write additional files, capture these into the cache
@bar TF #bar is a Seamless Transformer written in Python

foo x > y
x is a cache item; if there is a cell named "x", the cache item will be updated automatically
y will be the output cache item.
In the Shell language macro, this is mapped to the following:

tf = transformer({"input": {"pin": "input", "dtype": "json"}, {"result": {"pin": "output", "dtype": "text"})
ctx.CACHE["x"].connect(tf.input)
tf.result.connect(ctx.CACHE["y"])

Dollar variables: (the value of) uncached cells
Undollared variables: cache items (created directly or by cached cells).

The subcache commmand sets the current cache to ctx.CACHE[subcache]
"foo x > d/y" essentially maps to: "subcache d; foo x > y"
x is not found in the subcache, but still found in the parent cache, so the command proceeds

No if statements. No for loops. Only channel iteration using "with":
with $i #$i is a channel, but until "end", $i now refers to the item within the channel
  subcache $i
  foo x > y
end
If i = ["a", "b", "c"], this will create cache items "a/y", "b/y", "c/y"

with $i #$i is a channel, but until "end", $i now refers to the item within the channel
  subcache $i
  grep $i x > x2
  foo x2 > y
end
Here, a/x2 is created and used by foo.
To not cache x2, change it to $x2

There is the "glob" command to create a channel of cache item names
The "cd" command enforces the use of ../x to find the parent cache item x
y=../x creates a variable $y that refers to ../x

slashes and dots and items access is the same:
ctx.CACHE["x"]["y"] == ctx.CACHE["x","y"] == ctx.CACHE["x.y"] == ctx.CACHE["x/y"]
but not attribute access: ctx.CACHE.x.y is not allowed
caches also support aliasing:
ctx.CACHE.alias("x/y", "z")
ctx.CACHE["z"] now points to ctx.CACHE["x/y"]
The shell can do this with the "ln" command

Note that a shell script only works inside a MACRO
shell commands can be issued in any order! Exception: references to unknown cache items are collected and resolved when the outer shell macro finishes
"with" commands are further processed as MACROs that update whenever the channel changes!
The "clean" command cleans the cache of any cache items not created by cells or by the current shell script! "clean -r" descends into subcaches also!
