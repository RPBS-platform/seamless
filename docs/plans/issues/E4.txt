Seamless graphs as containers of computation results
====================================================

Seamless graphs contain the checksum of the computation results. However,
 currently they are not supported enough in this regard. 
In particular, if you load a graph and do ctx.compute(), Seamless will pull in all inputs,
erase all results, and recompute them, unless Redis provides:
- all the transformation result checksums
(which it already does, if is was previously used as a sink in the computation.
Therefore, no computation is re-done if Redis is present)
- all the expression result checksums
(which are not stored at all. Therefore, even if Redis is present,
all buffer input values will be pulled in!).

An important goal is to make the Seamless graph a self-consistent descriptor of
a computation result, i.e. if you load and do ctx.compute(), this is a no-op as
Seamless considers that no work nor value pull-in needs to be done. 

There are three solutions to this:
1. straightforward cases. 
For expressions, this is inchannels/input pins without celltype morphing.
For transformers, this is Python transformers. 
In these cases, the graph loading must be smarter. In that case, result checksums
 can be distilled from the graph and added to the cache, right before ctx.set_graph.
Of course, this must only be done if the graph is trusted.
One caching feature that must be added is Structured cell join caching. The input of a join
contains the checksum of auth and checksum dict of the inchannels. The output of the
join is the checksum of the buffer cell (the data cell is either the same, or None,
depending on the checksum of the schema; this must also be cached!).
2. Intermediate cases. This is expressions that involve celltype morphing, and
non-Python transformers. In this case, more checksums must be monitored/recorded
of the internal part. In addition, the graph must contain an explicit expression 
cache section.
3. Hard cases. This is Macros that have a non-empty internal low-level context
(as opposed to Macros that just connect incoming/outgoing paths dynamically).
Example of such a macro would be map-reduce, creating a transformer for every
data item in the input.
It will be very difficult to store this into a self-contained graph, since the observer
monitoring of standard cells and transformers is absent. This monitoring must be added
manually by the macro, and facilities must be added to pass this into the high-level for
storage!


