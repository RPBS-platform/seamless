Towards flexible and cloud-compatible evaluation / Seamless collaborative protocol
==================================================================================
(a.k.a the cloudless document)

Note (Jan 2020): This documents contains older plans about Seamless services
 and collaborative protocols. Probably obsolete, but may contain some useful nuggets.


## Thoughts on library
You don't import the seamless lib, you add it as a subcontext into your main
context (TODO: support loading subcontexts!!!; also, the .lib
context and its subcontexts must be copy-upon-assignment instead of rename-upon-assignment  ).
!!! lib mounter !!! normally, only read access. libdevel mounter with write access. Robogit (libgit2) to commit changes.
UPDATE: not exactly a "mounter"; core.lib system instead.
UPDATE: Seamless servers serve *high-level* contexts or transformers. They are contacted during translation.
 The context is *marked* by the high-level topology.
 In fact, there must be *two* service topologies (with checksums): a smaller one to *retrieve* the result;
  from this, evaluation and logging parameters (and workers that operate on them) should be stripped.
  And the full one to *compute* the result (which may still be refused, e.g. too many cores are requested).
 During (re-)translation, requests like create and delete can be sent.
 If the response is positive, then the cell checksums and values will be offered by the *low-level*.
 NOTE: the service checksum system must be a bit different from the semantic checksums used in local low-level evaluation.
  The reasons are 1. it is very difficult to compute a checksum for a code cell in an arbitrary programming language,
   unless a parser for that language has been installed; 2. service checksums will be global and therefore must be secure;
   semantic checksums are just to avoid unnecessary re-computation => use SHA3-512 for service checksums
 It is possible that the response is negative for the context-as-a-whole, but positive for sub-contexts and transformers
 Therefore, if there are multiple Seamless servers, they must be assigned a priority.
 Also, there is a spectrum between positive and negative: one server may accept the whole context, or even have the result cached,
  but another may accept only an empty context to which the cells must then be added (less efficient).

UPDATE:
Seamless services: Serve a (high-level) context, transformer or reactor; or a low-level transformer or reactor.
Services are substituted during graph translation:
  High level: send the high-level graph over the wire, together with cell updates.
  Low level: after finding a service, don't build a core.transformer, but a service.core.transformer
Local execution is a fallback, but service substitution can be enforced or disabled on an individual basis.
 (Also the kind of allowed services can be configured; services may promise fast execution, or not)
Service discovery happens with an explicit discover() command.
Common characteristic of services is that they synchronize cells.
When Seamless talks to a Seamless server, it offers a cell.
(UPDATE: this is not strictly true. Cell-cell connections between a serviced context
  and the outside world are indeed treated as state shared. However pin connections are exposed too!)
First, it provides the checksum. The server will then respond with one of the following responses ("transfer negotiation"):
 0. Server context is dead; client must re-initialize the server context and and re-send all cells.
    However, the context ID always stays the same.
 1. Cell checksum is already known and cached, no need to transfer
 2. Mounter is known; no need to transfer; server will retrieve cell value from mounter by itself
    UPDATE: seems like YAGNI
 3. Please transfer cell value
 4. The transfer of this cell or cell value is forbidden
 5. Reverse update request: the server asks the client to update one or more cells.
    This is most common in case of an interactive fix of the code (so the code cell has now a different checksum)
 6. Redirect (to another website). Maybe make this rare?
 7. Challenge. This server refuses secret cells. You must prove that you have the actual cell value.
 Server configuration involves primarily these responses.
 Other configuration is what kind of evaluation/resource-claiming meta-parameters to accept, and what kind of logging is returned.

 Type of servers:
 ### VERY NEW (Nov 2018) UPDATE: See "Seamless shared authority" below.
 0. will be ripped, and B. will be a special case of A.
 REST API and web sockets will be organized. 
 OLD:
 0. Dynamic HTML using websockets. Completely unrelated. UPDATE: ...and ripped
 A. Two-way synchronization (collaborative protocol). Uses websocket/crossbar server, pub/sub
    NOTE: text cells should support a git backend to resolve simultaneous edits on different sections of the text.
 B-D. One-way synchronization. Client manipulates cells, assuming that no other client does.
 B. Remote context server. Service is remote context server. It starts empty context (in Docker image)
    Returns a context ID / URL. The URL might be somewhere else.
    URL provides REST API:
    1. equilibrate
    2. set <cell name>
    3. read <cell name>
    4. create <cell name, worker, subcontext, etc.>
    5. delete <cell name, worker, subcontext, etc.>    
 C. Interactive service. As in B, but:
    - The server starts a full context, not an empty one.
    - 4. and 5. are forbidden
    - 2. is regulated. Some cells may not be set at all; for others, only certain values (or maximum sizes) may be acceptable.
    - 3. may be regulated as well
 D. Atomic service.
    1. Standard Seamless client. Negotiates cell transfer as in C.
     No concept of context ID.
     Returns a request URL: in a request, all cells are submitted, then
      the context is equilibrated, then the result is returned.
     Service configuration (internal):
     - Starts full context in Docker image (as in C)
     - One cell of the context must be marked as "result" cell, some others as input cells
     - Some cells may be marked as slow-changing. Contexts are kept alive, and when a request has the same values
       for the slow-changing cells, it is sent to the same context instance.
       This is just an implementation detail; it is assumed that this has no influence on context state.
   2. Web service. Non-Seamless client (Python, JavaScript, ...).
       As 1., but request URL is called directly.
       No transfer negotiation request, needs extra configuration to regulate this.
   3. Web server. As 2., but over CGI. Web form needs to (auto-)generated.
  Instead of Docker images, the service may also run on bare metal. It may even run in-process (dummy server).
  For atomic services, a HPC backend may be used as well (e.g. Slurm jobs).

Note that service *names* do not play any role. For logging purposes, one could be provided, otherwise it is just the local context name.

The idea is that the RPBS will host a global Seamless server (Cloudless) that accepts any context registration, and will
 be a *router* for services.
A server A, B, C, D1, D2, D3 and an HTML page for D3 are in principle auto-generated upon context registration, but customization is possible. For example, a cell may be designated as D3 HTML cell. Multiple D1 with multiple slow-change configs are possible.
After some time, context instances will be killed off, this can also be configured.
The RPBS server will have authorization: authorized registrations will have access to more resources.

How services are found:
At startup, Seamless server(s) and mounters are read from the environmental variables.
In the Seamless client, for any context, if a service is not found, Seamless reverts to local evaluation.
However, a context may be marked as "must be service".
A context may also be marked already with a context ID. The context ID is a huge (64 bit) global number that monotonically
 increases; the RPBS server guarantees that two interactive requests made under the same context ID will always modify the
 same context (as long as it is alive), no matter if they come from the same client or not.

Jupyter:
Jupyter is only useful for interactive servers and services (A-C). Seamless-in-a-notebook is an interactive client that
 can also in-line visualize HTML.
The RPBS server can offer interactive services as a "watermarked notebook". A notebook template is registered, and when a
 new context instance is created, the notebook is returned with the context ID filled in.
These notebooks can run everywhere: it can be downloaded and run locally, or at the RPBS. In the latter case,
 some "privileged connections" to the services can be set up in the form of mounters.
In the same vein, the RPBS will allow you to clone the entire RPBS server into a private sandbox copy,
and the URI will be similarly watermarked into the notebook. You can then override any service you like, without affecting
 other users.
Maybe every context submitted to an RPBS server should go into a robogit (libgit2) repo. Pull requests from sandbox server
 repos are then possible. (People should create their own Github account, then push the robogit@RPBS to there.
  RPBS should provide an in-Docker command line shell for this kind of thing)

Docker repo:
- Let apt/pip/conda/yum dump their state; define a Docker image as this state, on top of base Docker images
- The base images has all repo locations set to RPBS mirrors; for Ubuntu, PyPI, etc., all specific to a date and never changing
  This way we can guarantee version control and support indefinitely

Dependency server: Takes a dependency URN and gives some JSON as a result, preferably
with human-readable documentation and some kind of package name + version + checksum
in the format of apt/yum/pypi/conda.
Will be hosted at the RPBS.

OLDER THOUGHTS:

## UPDATE: Towards flexible and cloud-compatible evaluation
All (low-level) transformers and reactors will have a hidden JSON input pin "(sl_)evaluation".
For (low-level) macros, the presence or absence of "evaluation" is meta-parameter.
"evaluation" contains evaluation strategies. These are irrelevant to the *outcome* of the computation:
 the same result will be obtained no matter the evaluation strategy.
Seamless understands this, and merely a change in evaluation will not trigger a recompute.
The most obvious parameters are "synchronous"/"asynchronous", "process/thread", and the shared
state of Numpy arrays (binary data) and of plain-form data.
Less obvious ones: number of processors, force local (non-service) evaluation, force service evaluation
There will be a global fallback "evaluation" dict as well.
# UPDATE:
Don't follow exactly this scheme. Pins will now have simple evaluation parameters in their arguments.
Low-level macro caching will know that they don't matter.
In addition, a new cell type "evaluation cell" will be treated likewise.
This is just for the purpose of dependency tracking, though, not cache substitution (see above).
Evaluation cells may contain more complex evaluation parameters.
Their semantic meaning is at the high level, no low-level support or core mid-level support.


The seamless collaborative protocol (high level)
================================================

### UPDATE: completely outdated. See "Seamless shared authority" below.
The collaborative protocol is a means to share *cells*, like dynamic_html, but then bidirectionally
The idea is that a cell is bound to a unique "cell channel", so that two programs or web browsers can pub/sub to the channel
At the core, there is a single Seamless router (Crossbar instance) at the RPBS.
Websocketserver is gone: seamless looks for the router when it is initialized, or launches a "pocket router".
Every seamless kernel has its own ID, every context has its own ID, and every cell has its own ID. This triple of IDs forms the channel ID.
Seamless IDs are read from os.environ, else it is 0.
Seamless can expose its cell (for read or read/write) by registering itself as a channel with the Seamless router.
This opens an WAMP channels "seamless-host-{channelID}", "seamless-guest-{channelID}" and an RPC "seamless-state-{channelID}".
The seamless instance who registered the channel becomes the *host*, other clients can become *guests*
A guest can subscribe as follows:
- It subscribes to the *host* channel. Messages over the host channel are marked with a number N
- The guest invokes the state RPC, receiving back the state, and a number M, indicating the number of messages that were used to generate the state
- The guest can now  listen to messages. If the message N is not equal to M+1, the guest has to re-request the state (so packet loss is in principle possible!)  
- If read/write, the guest can now also publish to the *guest* channel. Only the host is subscribed to the guest channel.
The host sends every state change (both endogenous and those coming from the guest channel) over the host channel, and marks them with a number N. Guest channel messages are not numbered.
UPDATE: this replaces the Websocketserver, but not the parallel REST API.
UPDATE: It should be possible to send an (U)RI, instead of the cell value, over the network.
 The host and guest need to negotate in advance:
 - which protocols (HTTP, database, etc.) are accepted for URIs
 - which domains are acceptable. Both may have access to the same database, but not necessarily.
   (This is somewhat related to having this database as a mount backend, but not exactly)


Seamless shared authority
=========================

There are two concepts of shared authority: *context* authority and *cell* authority.
*context* authority regulates where a context graph is being computed. The *worker*
 performs the computation, whereas the *master* controls it. For each seamless instance,
 a context for which the seamless instance is the master but not the worker is a 
 *delegated context*.
For *cell* authority, the *host* owns and holds the data, whereas a *client* may request
or modify the data.
1. Context authority 
 The context consists of a context graph, the in-context cell values, the connections,
  and the values of the incoming connections. 
 Context authority can be interactive or non-interactive. 
 Non-interactive computing can be dumb or smart.
 For non-interactive computing, the mechanism is as follows:
  The master has any number of non-interactive workers, in the form of REST servers.
  Whenever the context is updated, a new *context request* is built. 
  A. In "dumb" mode, this request contains the entire context, including values. 
  This request is sent to a worker.
  Any previous context request is canceled. It is up to the worker to re-use pieces
  of earlier context requests (e.g preliminary results).  
  B. In "smart" mode, the master also acts as host of the cell values and connection values.
  It registers itself as host, providing identifiers for each cell and connection (see below).
  The context request all values are then replaced by the sharing handle (see below). 
  The worker may then act as client, requesting cell/connection values on demand. 
  The master may also ask: what about this graph? and get back some information on how easy
   it would be to execute.
  For any context request in any mode, the worker must either refuse quickly, return an error, or return the result (as either a value or as a sharing handle). 
The master has any number of interactive workers, in the form of REST servers.
The master may send the following requests, which a worker must quickly either acknowledge or refuse:
  - How busy are you? (Do you have free channels? A graph topology may be sent already)
  - Open a new channel (returns a channel ID; a graph topology may be sent already)
  On an opened channel:
  - (re)define graph topology (may include some values; flag can be defined to keep "internal cells")
  - Set cell/connection value
  - Get cell/connection value
  - Are you in equilibrium?
  - Shut down the channel (the worker is free to ignore this)
  In addition, the master may send "equilibrate", which may take a long time to answer.
  Every request is marked with an ascending ID, and the worker response is marked with the same ID.
  All values are sent as sharing handles. The master must register itself as host for them.
2. Cell authority
Cell authority can be local or remote. Local means that the state of the cell is maintained by the
 current seamless context. If it is remote, the state is maintained by a host elsewhere.
All cells can be set *by value* or *by checksum*. 
Setting by value always computes the checksum. Setting by checksum does nothing if the checksum stays the same.
Every cell that is not in a delegated context can be directly queried for its value.
(internal cells of delegated contexts may be queried from interactive workers, if the flag is set ).
Direct query of local cells gives the following result:
A. cell is None: return None
B. value mode: return value.
C. checksum mode: see below. 
3. Cell sharing
Local cells may be shared, which means that the current Seamless instance is their host.
(remote cells may also be shared, in which the Seamless instance is simply a router for that cell).
Cell sharing involves three operations:
3a. Publishing changes on the "cell share channel". Every Seamless instance may have exactly one
 channel, implemented as a websocket server. Upon connecting to the channel, a client will receive a share list (of shared cell names and types) and their checksums, and the global host marker. Whenever the host changes a shared cell, the change gets published on the cell share channel, and the host marker increases by one.
 Share lists may be registered under a "namespace". Clients indicate their preferred namespace
 in the path url (e.g, http://localhost/seamless/mynamespace:1234 for a cell share channel served on
 http://localhost/seamless:1234)
 The change is published as a share handle, of the format (cell name, checksum, host marker).
 Upon receiving the share handle, the client is expected to store it, together with the
  name of the host, if the client has more than one host.
 The other event that is being published is when the share list is being re-defined.
 (The high level should do this after re-translation, if there was no change)
 Internally, the host maintains for each shared cell what was the host marker that changed it
  most recently.
3b. Querying the "host channel". Every host has one, implementing five REST methods:
  - query value. The argument is a cell name. The host channel will return the cell value
    (including storage, form and/or schema, if applicable), the checksum, and the current host marker.
  - query update. The argument is a share handle. If the checksum is different than the stored one
    AND the host marker is later, return as above. Else, just return the current checksum + host marker. 
    If the host marker is earlier, then some routing has gone at different speed. In that case, the
     client should keep querying the update until the (routed) host catches up. Routing must always
     preserve the upstream host ID!
  - cancel all queries.
  - query set value (see 3c.)
  - set value (see 3c.)
  NOTE: at the high level, only one top-level context can expose shares for each namespace. 
  During context translation, for that namespace, both the cell share channel and the host channel should delay any response until the translation is done.
3c. Sending values to the host channel. 
A "query set value" can be done with just a shared handle. The host may send four possible responses:
- accept; please call "set value"
- reject; host marker is too old (i.e., the value has been updated in the meantime)
  The client will receive the current host marker in the response, and can use this to force the issue.
- success; submitted checksum found in cache (new host marker is returned)
- fail; cell is no longer shared.
Then, the value itself can be submitted with "set value", which returns the new host marker,
 or an error.

Querying checksum mode:
First, search local cache. If successful, return value.
Else, send a simultaneous request to all registered network cache servers. In addition, if the cell is remote, send a "query update" request to the host.
As soon as any network cache successfully yields a significant portion (depending on the value size) of the value, cancel all other cache requests. As soon as the full value has been obtained, if the cell is remote, cancel the host "query update" request, and return the value.
On the other hand, as soon as "query update" request starts yielding a value, cancel all network cache requests. When complete, return value.
If the cell is not remote, and network caching fails, report an error.
If "query update" returns the same handle, wait for the network cache. If it fails, query the host
with "query value".
If "query update" indicates a routing delay, run "query update" until solved, then run "query value".

After any cell (local or remote) in checksum mode has been successfully queried/retrieved from cache, it enters value mode. But Seamless is free to put any cell back in checksum mode, adding its value to local cache.
Local cache must not discard a value as long as any cell in checksum mode holds on to it, although it may offload to network cache (under the same constraints).


NOTE: transformer authority is a special case of context authority. It has the same modes
(interactive, non-interactive smart, and non-interactive dumb).
Transformer authority and cell authority are maintained at the low level. Context authority
 at the high level.
NOTE: There can be only one interactive and one non-interactive worker, but cluster managers
 can function as one virtual worker. They can deal with all kinds of meta-parameters, and do
 smart dispatch based on the contents of the graphs and values.

