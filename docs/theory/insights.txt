Theoretical insights
====================

(Needs some reformulation...)

Seamless focuses on decomposing a program that is Turing-complete into components.
It is not about *concrete* decomposition, which concerns itself with reusability,
 code clarity, etc. (this is a software engineering thing)
Rather, it concerns itself with *abstract* decomposition, i.e. how to define 
 elegant primitives of which any program can be composed. Composition is using a call graph.
Programming languages do this also, but there, the primitives are not Turing-complete,
 only the composition is.
In contrast, Seamless is an "inter-Turing language": it is about composing primitives that are by themselves already Turing complete. An inter-Turing language is concerned about the syntax and semantics of dependency graphs, and is completely disjoint from the syntax of the primitives. The primitives have their own namespace (Turing tape),
which must be explicitly connected by the inter-Turing language. Seamless has a universal primitive for data transformation, which models source code as just another data input. It does not prescribe a syntax for this source code: any programming language can be used, as long as its execution has referential transparency. Seamless does not enforce this, violation simply leads to undefined behavior. 
Similar languages: Linda, Data flow programming, Notebooks.

Seamless is purely functional, reactive and interactive
Purely functional => determinism and referential transparency, and side effects don't matter
Interactive: You can modify the call graph while it is being executed
Reactive: Seamless automatically reacts to changes

Bash is inter-Turing and somewhat interactive, but not functional.
Notebooks are interactive and somewhat inter-Turing: however, they share the same code namespace and variable namespace, unlike Bash. Magics can be used to regulate this.
Neither Bash nor Notebooks are reactive. Since they are imperative, re-execution is expensive.
GHCI is interactive but not inter-Turing and not reactive: if you re-define a function, expressions do not get updated. Therefore, while Haskell is functional, GHCI is not functionally reactive.
Spreadsheets are functionally reactive and interactive.
purely functional in the sense that they connect the cells and 
 insert their values into the cell code.
Cell code itself is imperative (for Excel: Visual Basic)
Spreadsheets are not truly inter-Turing because they share the same code namespace
 (like Notebooks)
***Insight***: functional + reactive + caching makes trivially interactive: just re-evaluate the call graph every second!
Gnu Make (and SnakeMake) is inter-Turing, functional and reactive (and trivially interactive)
Still, it is a bad (de)composition tool because it composes binaries that have been compiled and installed. No access to the compilation Makefiles of those binaries, or to the installation scripts (which can be in a functional language, e.g Nix).
So you cannot decompose a Makefile all the way down to the source code of the
 individual binaries. This is only OK if the binaries have a formal spec regardless
 of implementation (POSIX), otherwise it is not portable/reproducible.
File modification time as a proxy for true (checksum-based) reactivity, bad!
Worse: files can be modified externally, breaking determinism.
Dataflows are bad because they treat data and code differently.
Dataflow frameworks are often reactive towards data cells, but never towards code.
I know of no dataflow framework that allows interactive programming with
 separate namespaces for each code cell (inter-Turing).
Things like Galaxy are somewhere halfway between (Snake)Make and dataflow, sharing
 at least some of the vices of each.

Notebooks are bad because there *are* no data cells, only code cells.
Typically, there is only one namespace, and typically, the call graph is
strictly linear.
Spreadsheets are bad because they mix composition syntax (purely functional) 
 and evaluation syntax (imperative) and have a single code namespace.
 This makes it very hard to make polyglot spreadsheets.
Seamless has a strong opinion about what it means to assign a cell's value.
It is either an *evaluation assignment*, which means that it happens *once*,
or an *authority assignment*. Assignments are constant.
Seamless *cells* are not constant (in the sense that variables in functional 
programming and mathematics are constant) but Seamless *checksums* are.
Therefore, evaluation assignment happens once, but Seamless reacts to
 *authority assignment*, which is: changing a cell that is not the output of
an operation. Authority assignments can happen from the terminal, over the network
(shareserver), or from a reactor. Seamless treats them all the same. An authority
assignment discards the previous value of a cell, a cell's history is not modelled.
This is the same as a spreadsheet, but different from FRP and reactive frameworks in imperative languages, which explicitly model the dynamic behavior of values (as event streams).
Seamless is also a functional language in the what-not-how sense. Let's take for example a piece of Python code "result = sorted(table)".
This can be applied to a simple array cell ctx.table, with a 2D Numpy array. But ctx.table could also be a deep cell may span terabytes,
 with each fragment checksum cached at different remote locations. In that case, it makes perfect sense for a Seamless implementation to
 interpret "result = sorted(table)" as a Spark query. ctx.table can be converted to a Spark RDD on the fly, or it may already be a persistent
 RDD, identified by a checksum-to-RDD cache server. The result will then be converted back from an RDD to another deep cell (using caching), or to a normal array cell (using a Spark action). Seamless does not care, since in terms of checksum calculus, the result is the same
 (except of course that deep cells do not have a single checksum describing the whole data, but a framework like Spark could compute one).

Seamless provides provenance by reverse referential transparency: instead of replacing a computation by its value,
a value is replaced by its computation. Obviously, this only works for unique values.