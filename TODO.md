UPDATE OF THE UPDATE
Great Refactor is underway (see seamless-toward-02.md).
Most of the text below the FIRST section is out of date.
Current status: simplest low-level example works.
Things to do (all low level) :
- mixedcell serialization
- symlinks  (may be exported; eliminate ExportedPin)
- cson cells
- Simple macros (no caching)
  NOTE: (low-level) contexts generated by macros must be *sealed*:
  - No children may be added to the context after sealing
  - Connections may only be added between A and B, where
    A is an exported child of the context, and B is a child of the direct parent context
    These connections must be built either a) in the macro that creates the direct parent context,
    or b) in a connection layer of the direct parent context
  - When a parent context is sealed, so will all child contexts
  This is essential for proper caching; once a parent context is being sealed, the children
   are evaluated for cache hits (value hits).
- Reactors (think of IPython stuff in the namespace, not properly addressed in 0.1; copy from 0.2 transformers)
  (also think of \_pending_inputs: add a name back in, if sent as None (like transformers))
- "Active" switch of managers, workers, connections; persistent/serialized or not?? => maybe export switches, and add to connection layer
- PyImport cells and code injection
- Status dict, also as a structured cell  (also policies like .accept_shell_append)
- Signatures/checksums and macro caching. NOTE: take care of the alternative checksums caused by "cosmetic updates"
  (NOTE: macro caching is a low-level thing, because at the high-level, it is just a change-of-value of the macro parameter, no topology change!)
  Macro caching can give a topology hit (if the macro code and macro args are the same), and the resulting context may give value hits
   (depend on the value of the connected cells)
Then, slowly move to the mid-level data structure:
UPDATE: maybe elide the middle level, dynamically generate at time of low-level generation/serialization??
- manager observers (not needed ?)
- low-level-to-mid-level mapping (as observers) (not needed ?)
- apply to slash-0 (see mount.py:filehash)
- design mid-level, including old resources
Finally, the high level:
- serialization (take care of shells also).

/FIRST section, beyond here is mostly out of date

UPDATE:
The following roadmap is outdated by the new conception of Silk as a schema language,
and the new high-level API
The topics are either:
- Explicitly covered by Silk/the high level API (see the docs there)
- Easily implemented at the library level, thanks to the high level API.
- Mechanics-based, and therefore unchanged (e.g. thread-based/process-based,
  sync/async workers)
That leaves three things to take care of:
(1) Macros that take a context argument (but I think this is documented already?)
(2) Event streams
(3) Equilibrium contexts.

(2) Event streams receive event values, or a "undo" signal, which means that all previous
values are invalid. Event streams may send back a "send again" signal, which means
that they want again all values that were previously sent to them. (This is for example if a transformer adds 5 to an event stream; if 5 is changed to 6, either in a input cell or by a change in the source code, the transformer will send a "send again" signal upstream).
Reactors may choose to cache events so to avoid sending this signal when one of their other inputs changes.
Finally, there are the "initialize" and "disconnect" signals.
Event stream inputpins are in a state where they accept a new value, or they don't. Force-feeding is possible, in that case the values are buffered up by seamless itself.
Workers must always declare explicitly a pin as event stream.
Transformers don't need any change in their code. However, if one or more of their inputs is an event stream, so must be their output (vice versa is not required, but if all inputs are cells, a transformer that has an event stream as output must return a list, which is force-fed into the event stream after sending an "initialize" signal).
Reactors must push/pull new event stream values in an explicit API:
  - blocking waits for it
  - non-blocking essentially sets to event stream input pin to "accept input" (input) or force-feeds (output)
  - By default, input is blocking while output is non-blocking
Event streams can never be authoritative, they must depend on a worker.

(3) Transformers are guaranteed not to send anything (be it cell values or events) on their primary output until execution has finished (which means they are in equilibrium).
In addition, transformers are guaranteed not to accept any events while not in equilibrium.
This is obviously not so for reactors, and it is also not so for contexts that contain reactors (or multiple transformers that are not arranged linearly) connected to context outputs.
It is possible to declare contexts as "equilibrium contexts". In that case, they have the same guarantees as transformers have: sending cell updates or events to the outside world is delayed until equilibrium is reached, and so is the acceptance of new events. This allows contexts to perform atomic computations, reducing the number of glitches.
It is possible to declare some of the outputs (and event stream inputs) as "secondary", which means that they escape this guarantee (for example, for logging purposes).






Technically-oriented releases are marked with *

\*0.1
After release, make videos:
  Basic example, based on examples/basic.py, then examples/basic-macro.py
  Fireworks
  3D
  Docking
  Orca (don't show the code)

0.2

- macros
I am not quite happy with how macros are being used. The direct import method
(defined macro "spam" in "eggs.py", "from eggs import spam") is fine for the
core macros, but it hampers live programming on other macros (though it isn't
prevented completely ; see test-dynamic-macro.py for an API example),
since it prohibits the link between macro <=> cell <=> file.
To solve that, a function .load_macro("spam", "eggs.py") is needed, that creates
a macro with a .cell attribute, with .cell.resource.filepath
(and .resource.lib) set properly. The .cell can be link()'ed as usual.
In addition, the function .load_block_macro("ham", "ham.py") loads ham.py as a
code block, i.e. adding "@macro", a def, and indenting the code.
ham.py can thus be a main script, like the ones in tests and examples.
For all main scripts in tests and examples, the "ctx = " and ctx.tofile
must be made conditional on __name__ == "__main__"

- Overhaul dtypes.objects, in particular the Python code blocks
  Allow Python blocks to be parsed by the transformer without return.
  Transformer execution is still prohibited without return, unless the transformer has no outputpin.
- Give a .as_cell() method every worker and context. This cell will contain a text representation
  (essentially invoking X_to_json).
  In the Python register, allow transformer.as_cell() to be registered as a Python function,
  and context/reactor.as_cell() as a Python class
- Replace the use of killable threads with processes... gives a problem with Orca example (fixed now ?), docking example (?), see Github issue
- Replace ctx.CHILDREN, ctx.CELLS etc. with ctx.self.children, ctx.self.cells, etc.
- Get rid of seamless.qt
- Composite (JSON) cells
- Expand and document seamless shell language (slash)
- Logging + dtype/worker documentation.resource system (using composite cells)
- Error message logging system (using composite cells)
- Overhaul dtypes, docson/type registration API, integrate with logging/documentation system. "array" and "json" are no longer dtypes, but formats
- Update demos

\*0.3
- Multiple code cells in transformers/reactors
- Preliminary outputpins (in transformers [as secondary output] and in reactors)
- Preliminary inputpins (pins that accept preliminary values). Right now, all inputpins are preliminary!
- Address shell() memory leak: IPython references may hold onto large amounts of data
- Address GLstore memory leak: stores may not be freed (?)
- Binary (struct) cells, implemented as structured "array" cells with dtype/shape/ndim (with functionality similarly to composite cells)
- Active switches (connection level; workers don't see it, except that pin becomes undefined/changes value)
- Silk: managing variable-length arrays with allocators (subclass ndarray), C header registrar, fix Bool default value bug + bug in examples/silk/test.py
- Document Silk, make it an official (supported) part of seamless
- C interop
- Game of Life demo with Cython and C
- Update OpenGL demos

0.4
- Finalize context graph format and their names, update tofile/fromfile accordingly
- Finalize resource management
- Finalize basic API, also how to change macros (SEE ABOVE)
- Cleanup code layout
- Document tofile/fromfile, saving options and seamless file format
- Code documentation + dtype/worker documentation system
- Set up user library directory and robogit
- Update demos

\*0.5
- Thread reactors, process reactors
- Synchronous transformers (do we need this?)
- Process transformers (now that execution is in a process, do we need this??)
- Cell arrays, channels, GUI-widget cells
- GPU computing (OpenCL)
- Update Game of Life demo

0.6
- Hook API and GUI for cell creation
- Update demos

0.7
- ATC, fold/unfold switches, Silk GUI generation
- More demos (tetris?)

\*0.8
- Python debugging, code editor (WIP)

\*0.9
- Collaborative protocol / delegated computing

\*1.0
- Lazy evaluation, GPU-GPU triggering
